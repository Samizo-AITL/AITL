# Chapter 3: Logic Layer – LLM-Driven Inference  
## 論理層：LLMによる推論と仕様生成

---

## 3.1 論理層とは

AITLにおける**論理層（Logic Layer）**は、設計対象の「**目的・意図・文脈**」を処理し、制御層が実行可能な命令へと変換する役割を担います。

この層では主に以下のような機能を実装します：

- 自然言語入力の解釈（例：「障害物を避けて移動せよ」）
- 状況依存の意思決定（例：「地形条件に応じたルート選択」）
- 制御仕様の生成（例：「軌道=回避半径1.5m、速度制限=1.2m/s」）

これらの処理を、近年急速に発展している **大規模言語モデル（LLM）** により実現します。

---

## 3.2 LLMとは何か？

LLM（Large Language Model）は、数十億〜数千億のパラメータを持つ自然言語処理モデルであり、以下の特性があります：

- 文脈理解と推論が可能（Transformerベース）  
- 仕様・設計意図を人間と同様に「読解」し応答  
- 近年では組込み向けの軽量モデル（TinyLM, Phi, LLaMA2など）も登場

---

## 3.3 LLMによる仕様生成の例

### 例：自然言語入力
「前方に障害物がある場合、左側を回避しながら速度を0.8m/s以下に制限して前進する」

### 推論結果（構造化出力）

```json
{
  "avoidance_direction": "left",
  "target_speed": 0.8,
  "trigger_condition": "obstacle_detected",
  "control_mode": "trajectory_adjustment"
}
```

このように、非形式的な自然言語仕様を構造化データとして制御層に渡すことができます。

---

## 3.4 LLMをSoCへ組み込むには？

LLMを実装に活用するためには、以下の3つのアーキテクチャ的選択肢があります：

| 構成                      | 特徴                               | 課題                           |
|---------------------------|----------------------------------|------------------------------|
| オンチップ軽量LLM         | リアルタイム応答が可能、エッジ用途に有効 | モデル圧縮・量子化が必要、精度低下リスク |
| 外部プロセッサ連携（NPU等） | AI処理を分離可能、高性能                | バス設計・電力管理が複雑            |
| ハイブリッド（クラウド/エッジ連携） | 高精度なLLMを活用可能                 | 通信遅延・プライバシーリスク          |

特にFPGA構成では、**LLMの小型推論エンジンをIPとして統合**する構想が進行中です（例：AITL PoC in SkyEdge）。

---

## 3.5 実装のステップ

1. **プロンプト設計**：意図や仕様を記述した自然言語テンプレートを用意  
2. **LLM推論**：ChatGPT、LLaMA2、Phi等を使い仕様生成  
3. **構造化変換**：JSONやFSM（状態機械）に変換し制御層へ入力  
4. **バリデーション**：出力結果が設計要件に適合しているか検証

---

## 3.6 教育的活用と課題

- 学生は**仕様記述→プロンプト設計→構造化変換**という実践的プロセスを学べる  
- 論理層の設計は、**AIリテラシーとハードウェア設計の橋渡し**となる  
- 一方で、LLMは「確率的な回答」であるため、**出力の検証**が不可欠

---

## 次章予告

次章では、論理層の出力を受けて具体的な制御動作を担う **制御層（Control Layer）** を解説します。  
ここでは、Simulink / Stateflow によるモデル設計、状態遷移、フィードバック制御の基本を学びます。

---

