# 🧠 LLM 推論ロジック設計書

本ドキュメントでは、LLM（理性）側の判断基準と出力方針について定義する。

---

## 🎯 目的

- ユーザーの感情・発話・表情をもとに、最適な状態と応答を提案する
- FSMが判断可能な構造で出力する
- ユーザーが「寄り添われた」と感じる文脈的応答を実現する

---

## 🟨 入力形式（emotion_input.json）

```json
{
  "timestamp": "2025-07-02T15:30:00+09:00",
  "user_id": "elder_01",
  "emotion": "sad",
  "voice_text": "今日はなんだか寂しいな",
  "face_expression": "frown",
  "pose": "sitting"
}
```

---

## 🔁 推論処理の流れ

1. 感情 + 音声テキスト + 表情から「文脈ラベル」を推定
2. 文脈に応じて、以下の2つを生成：
    - `suggested_state`（例：CARE_MODE）
    - `response_text`（例：「寂しい日もありますよね。今日は何があったのですか？」）
3. 出力を `llm_response.json` 形式で返却

---

## 📤 出力形式（llm_response.json）

```json
{
  "suggested_state": "CARE_MODE",
  "response_text": "寂しい日もありますよね。今日は何があったのですか？"
}
```

---

## 🤖 LLMの役割と設計方針

| 項目             | 設計内容                                           |
|------------------|----------------------------------------------------|
| 推論対象         | emotion, voice_text, face_expression, pose         |
| 出力形式         | JSON（状態＋応答文）                               |
| 応答文の特徴     | 共感・安心・自然な会話                             |
| 安全対応         | 不適切ワード・異常フラグがあれば `ALERT_MODE` に誘導 |
| 実装方式         | OpenAI GPT / ローカルLLM / プロンプトテンプレート  |

---

## 🧪 テスト観点

- 入力パターン別の状態分類精度
- 応答の自然さと安心感
- FSMとの状態一致率（整合性チェック）

---

この設計により、FSM（本能）の動作と協調しつつ、より人間らしい柔軟な判断と対話を実現する。
