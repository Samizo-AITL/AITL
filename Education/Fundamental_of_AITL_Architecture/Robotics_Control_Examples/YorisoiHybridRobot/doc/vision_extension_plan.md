# 👁️ 画像認識拡張構想（CMOSビジョン統合）

本ドキュメントでは、将来的にCMOSカメラ・画像認識による入力をFSM/LLM制御に統合する構想を示す。

---

## 🎯 拡張目的

- 表情・動作・環境を映像から認識し、FSM制御とLLM判断の精度を向上
- 単一センサ（音声・感情）に依存しないマルチモーダル認識を実現
- 「見て寄り添う」人型ロボットとしての信頼性を強化

---

## 🔧 ハードウェア想定構成

| 要素           | 内容                            |
|----------------|---------------------------------|
| CMOSカメラ     | 解像度720p以上、30fps以上        |
| 入力IF         | USB/UVC or MIPI-CSI              |
| 処理系         | Raspberry Pi / Jetson / FPGA等   |

---

## 🧠 ソフト処理構成

```text
CMOS映像 → 画像処理 → 特徴抽出 → 判定 → FSM/LLM入力
```

| 処理ステージ     | 内容                                        |
|------------------|---------------------------------------------|
| 顔検出           | 顔の有無・領域検出（OpenCVなど）           |
| 表情認識         | joy / sad / angry / neutralなど分類         |
| 姿勢認識         | 座る・立つ・転倒などの推定（pose estimation）|
| 周囲認識         | 人の有無・室内/屋外判定など                 |

---

## 🔄 FSM/LLM連携方法（将来対応）

| データ             | FSM連携             | LLM連携                 |
|--------------------|---------------------|--------------------------|
| 表情分類           | 状態遷移条件に追加  | 応答文のトーン調整      |
| 姿勢分類           | REST誘導やSAFE判定  | 疲労検知・優しい対応    |
| 周囲状況（照明など）| ALERT条件に追加     | 声かけ文調整など        |

---

## 🚧 開発ステージ（予定）

| ステップ         | 内容                                       |
|------------------|--------------------------------------------|
| Step 1           | OpenCV+MediaPipe等による表情・姿勢認識    |
| Step 2           | FSM入力に画像分類出力を連携                |
| Step 3           | LLM入力プロンプトに画像情報を追加          |
| Step 4           | マルチモーダル統合（音声＋映像）実現      |

---

この拡張により、「聞いて、見て、寄り添う」人型ロボットへと進化可能となる。
